{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32943236-77bb-4ca2-b85d-96433f97b4ad",
   "metadata": {},
   "source": [
    "# Projeto 1 de Grafos\n",
    "### Disciplina: Teoria e Aplicação de Grafos — UnB\n",
    "### Turma: 01, 2025/2\n",
    "### Professor: Díbio\n",
    "\n",
    "## Integrantes:\n",
    " - Júlia Paulo Amorim - 241039270\n",
    " - Letícia Gonçalves Bomfim - 241002411\n",
    " - Vitor Alencar Ribeiro - 231036292\n",
    "\n",
    "O link da página do repositório é: <https://github.com/LetiBomfim/Projeto-Grafos-1>\n",
    "\n",
    "O link para clone do repositório é: https://github.com/LetiBomfim/Projeto-Grafos-1.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8002c5-bc63-4a59-8ebb-d6a9f28e52d8",
   "metadata": {},
   "source": [
    "\n",
    "## Aqui descreveremos as instruções de quais extensões devem ser baixadas e como rodar o projeto para Linux\n",
    "    1 - Verificar se python está instalado com python3 --version\n",
    "    2 - Instalar o pip com sudo apt install python3-pip\n",
    "    3 - Crie um ambiente virtual (se quiser) para rodar o projeto com python3 -m venv venv\n",
    "    4 - Ative o ambiente virtual com source venv/bin/activate\n",
    "    5 - Instale as dependências do projeto com pip install networkx numpy matplotlib requests scipy python-louvain\n",
    "    6 - Para rodar o projeto, utilize python3 facebook.py\n",
    "    7 - Já em relação ao relatório, baixe o Jupyter notebook com pip install jupyterlab\n",
    "    8 - Para iniciar o Jupyter, inicie o comando jupyter lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41cae9-f1fb-4206-8232-8390630766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports do grafo:\n",
    "import networkx as nx  #Manipula gráficos\n",
    "import requests  #Faz o download de dados por HTTP\n",
    "import numpy as np  #Auxilia nas operações numéricas\n",
    "import matplotlib.pyplot as plt  #Possibilita a visualização dos gráficos\n",
    "import community as community_louvain  #Detecta as comunidades\n",
    "from matplotlib.patches import Patch  #Possibilita a criação das legendas personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a82eff-e96d-469f-be97-354da313628e",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 1 - Coleta de Dados:\n",
    "\n",
    "O processo envolve o download do arquivo compactado de arestas e a gravação local em disco, garantindo que o grafo possa ser carregado nas etapas seguintes.\n",
    "    \n",
    "> Como a Etapa Foi Implementada:\n",
    "- Download Automático: O método baixar_dados() utiliza uma requisição HTTP para acessar diretamente o dataset hospedado no site oficial da Universidade de Stanford (SNAP), onde está armazenado o grafo \"facebook_combined.txt.gz\".\n",
    "- Verificação de Sucesso: Caso o download seja bem-sucedido, o arquivo é salvo localmente e uma mensagem de confirmação é exibida; caso contrário, o erro é tratado e descrito no terminal.\n",
    "\n",
    "> Bibliotecas Escolhidas:\n",
    "- Requests: A biblioteca `requests` é a ferramenta padrão e mais estável em Python para comunicações HTTP. Foi escolhida por sua simplicidade, confiabilidade e por permitir o tratamento direto de exceções (com o método raise_for_status), evitando falhas silenciosas durante o download.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d8438-bbae-4857-bd75-f1e190b3f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacebookGraph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.G = None\n",
    "        self.G_subset = None\n",
    "\n",
    "    def baixar_dados(self):\n",
    "        url = \"https://snap.stanford.edu/data/facebook_combined.txt.gz\"\n",
    "\n",
    "        try:\n",
    "            #Requests é uma biblioteca cliente HTTP para Python\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            #Abre o arquivo com as arestas\n",
    "            with open(\"facebook_combined.txt.gz\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(\"Arquivo aberto com sucesso!\\n\")\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Não foi possível abrir o arquivo: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74766f10-777a-4f68-9aa4-0f719e17a6eb",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 2 - Construir o grafo:\n",
    "\n",
    "Esta etapa cumpre a segunda parte do projeto: transformar os dados baixados em uma estrutura de grafo manipulável e gerar um subgrafo com 2000 nós para análises subsequentes.\n",
    "     \n",
    "> Como a Etapa Foi Implementada:\n",
    "- Carregamento da Rede: O método carregar_rede() usa uma função nativa do NetworkX que interpreta automaticamente o arquivo de lista de arestas (.txt.gz) e cria um grafo não direcionado. Em seguida, são impressas métricas básicas — número de nós, arestas e densidade — que servem como uma validação inicial do dataset.\n",
    "- Seleção Aleatória de Nós: O método extrair_subconjunto() faz uma amostragem aleatória de 2000 vértices do grafo principal. Essa abordagem reduz a complexidade computacional e permite que o restante da análise (centralidades e comunidades) seja executado de forma eficiente.\n",
    "- Construção do Subgrafo: Após a seleção, é criado um subgrafo contendo apenas os nós sorteados e suas arestas internas. Assim, garante-se que o subconjunto preserve a estrutura original de conexões entre os nós escolhidos.\n",
    "\n",
    "> Bibliotecas Escolhidas:\n",
    "- NetworkX: É a principal biblioteca Python para modelagem e análise de grafos. Ela permite ler o arquivo de arestas diretamente e fornece métodos prontos para criar subgrafos, calcular densidade e realizar inspeções estruturais.\n",
    "- NumPy: Utilizada aqui pela função `np.random.choice`, que oferece uma maneira eficiente e reproduzível de selecionar nós aleatórios sem repetição (replace=False), garantindo uma amostragem equilibrada da rede.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c91dc-d17a-4fa0-8a91-20162cf31b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def carregar_rede(self):\n",
    "        try:\n",
    "            #Função nativa do NetworkX que lê um arquivo de lista de arestas e cria um grafo\n",
    "            self.G = nx.read_edgelist(\"facebook_combined.txt.gz\")\n",
    "\n",
    "            #Teste se criou o grafo corretamente\n",
    "            print(f\" - Nós: {self.G.number_of_nodes()}\")          #4039\n",
    "            print(f\" - Arestas: {self.G.number_of_edges()}\")      #88234\n",
    "            print(f\" - Densidade: {nx.density(self.G):.6f}\")      #0.010820\n",
    "\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar grafo: {e}\")\n",
    "            return False\n",
    "            \n",
    "        #Parte da Etapa 1 - Extrair desse grafo carregado 2 mil vértices\n",
    "        \n",
    "    def extrair_subconjunto(self, n_nos=2000):\n",
    "        if self.G is None:\n",
    "            print(\"O grafo não existe!\")\n",
    "            return False\n",
    "        \n",
    "        todos_nos = list(self.G.nodes())\n",
    "        #Utiliza a biblioteca numpy para escolher nós aleatórios dentre os da lista\n",
    "        #replace=False é para não haver repetição de nós\n",
    "        nos_selecionados = np.random.choice(todos_nos, size=n_nos, replace=False)\n",
    "\n",
    "        #G_subset é o subgrafo com os 2000 selecionados\n",
    "        self.G_subset = self.G.subgraph(nos_selecionados).copy()\n",
    "\n",
    "        for node in nos_selecionados:\n",
    "            vizinhos = list(self.G.neighbors(node))\n",
    "            for vizinho in vizinhos:\n",
    "                if vizinho in nos_selecionados:\n",
    "                    self.G_subset.add_edge(node, vizinho)\n",
    "\n",
    "        print(\"\\nInformações gerais dos 2000 nós selecionados:\")\n",
    "        print(f\" - Nós: {self.G_subset.number_of_nodes()}\")\n",
    "        print(f\" - Arestas: {self.G_subset.number_of_edges()}\")\n",
    "        print(f\" - Densidade: {nx.density(self.G_subset):.6f}\")\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc45c972-b237-4e38-b449-368496b7abd2",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 3 - Extrair do grafo as métricas:\n",
    "\n",
    "Este bloco de código foi desenvolvido para cumprir a Etapa 3 do projeto, que exige a extração de métricas de centralidade e o mapeamento de comunidades da rede social. A implementação foi feita dentro do método `calcular_metricas()` para manter a organização e a modularidade do código.\n",
    "    \n",
    "> Como a Análise Foi Implementada:\n",
    "\n",
    "O método calcular_metricas() segue uma lógica sequencial e clara:\n",
    "\n",
    "- Centralização: Todas as análises foram agrupadas em uma única função para facilitar a execução e a manutenção do código.\n",
    "- Cálculo das Métricas: Para cada uma das quatro medidas de centralidade (Grau, Intermediação, Proximidade e Autovetor), o código chama uma função específica e otimizada da biblioteca NetworkX.\n",
    "- Identificação dos Nós Influentes: Após cada cálculo, o código ordena os resultados e imprime no terminal os 5 nós mais importantes (o \"Top 5\") para aquela métrica. Isso fornece uma visão imediata de quais \"usuários\" são mais influentes em diferentes aspectos da rede, informação crucial para o relatório final.\n",
    "- Detecção de Comunidades: Utiliza-se a biblioteca community para aplicar o algoritmo de Louvain, conforme exigido pelo enunciado do projeto, identificando os principais agrupamentos (\"panelinhas\") na rede.\n",
    "- Armazenamento: Todos os resultados são salvos em variáveis da classe, permitindo que sejam facilmente acessados por outras funções, como a de visualização, para criar os grafos coloridos e rotulados.\n",
    "\n",
    "> Bibliotecas Escolhidas:\n",
    "\n",
    "A escolha das bibliotecas foi baseada nas que mais fazem sentido nos requisitos do projeto:\n",
    "\n",
    "- NetworkX: É a biblioteca padrão-ouro para análise de grafos em Python, explicitamente recomendada nas instruções do trabalho. A principal vantagem é que ela já possui implementações robustas e academicamente validadas de todos os algoritmos de centralidade necessários. Isso elimina a necessidade de programar essas complexas rotinas matemáticas do zero, garantindo a precisão dos resultados e a simplicidade do código.\n",
    "- Python-louvain (importada como community): O enunciado do projeto exige especificamente o \"Mapeamento de comunidades pelo algoritmo de Louvain\". A biblioteca python-louvain é a implementação padrão deste método para Python e se integra perfeitamente com objetos de grafo do NetworkX. A escolha, portanto, foi a mais direta para cumprir este requisito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f2cc9-6d6b-45ae-b5e6-3683a4e367c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def calcular_metricas(self, top_n=5):\n",
    "        #Calcula as métricas de centralidade e detecta comunidades no subgrafo.\n",
    "        if self.G_subset is None:\n",
    "            print(\"O subgrafo não existe! Execute extrair_subconjunto() primeiro.\")\n",
    "            return False\n",
    "        \n",
    "        print(\"\\n--- CALCULANDO MÉTRICAS DE CENTRALIDADE E COMUNIDADES ---\")\n",
    "        \n",
    "        try:\n",
    "            #Degree Centrality\n",
    "            print(\"\\n[1] Grau de Centralidade (Degree):\")\n",
    "            print(\"Mede a popularidade de um nó pelo número de conexões diretas.\")\n",
    "            degree_centrality = nx.degree_centrality(self.G_subset)\n",
    "            sorted_degree = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Grau de Centralidade:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_degree[i][0]}: {sorted_degree[i][1]:.4f}\")\n",
    "\n",
    "            #Betweenness Centrality\n",
    "            print(\"\\n[2] Centralidade de Intermediação (Betweenness):\")\n",
    "            print(\"Mede a importância de um nó como 'ponte' nos caminhos mais curtos entre outros nós.\")\n",
    "            betweenness_centrality = nx.betweenness_centrality(self.G_subset)\n",
    "            sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Centralidade de Intermediação:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_betweenness[i][0]}: {sorted_betweenness[i][1]:.4f}\")\n",
    "\n",
    "            #Closeness Centrality\n",
    "            print(\"\\n[3] Centralidade de Proximidade (Closeness):\")\n",
    "            print(\"Mede quão rápido um nó consegue alcançar todos os outros na rede.\")\n",
    "            closeness_centrality = nx.closeness_centrality(self.G_subset)\n",
    "            sorted_closeness = sorted(closeness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Centralidade de Proximidade:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_closeness[i][0]}: {sorted_closeness[i][1]:.4f}\")\n",
    "\n",
    "            #Eigenvector Centrality\n",
    "            print(\"\\n[4] Centralidade de Autovetor (Eigenvector):\")\n",
    "            print(\"Mede a influência de um nó com base na importância de seus vizinhos.\")\n",
    "            try:\n",
    "                eigenvector_centrality = nx.eigenvector_centrality(self.G_subset, max_iter=1000)\n",
    "                sorted_eigenvector = sorted(eigenvector_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "                print(f\"  Top {top_n} nós com maior Centralidade de Autovetor:\")\n",
    "                for i in range(top_n):\n",
    "                    print(f\"    {i+1}. Nó {sorted_eigenvector[i][0]}: {sorted_eigenvector[i][1]:.4f}\")\n",
    "            except nx.PowerIterationFailedConvergence:\n",
    "                print(\"  Cálculo de autovetor não convergiu. Pulando esta métrica.\")\n",
    "\n",
    "            #Algoritmo de Louvain\n",
    "            print(\"\\n[5] Mapeamento de Comunidades (Louvain):\")\n",
    "            print(\"Agrupa os nós em 'panelinhas' onde as conexões internas são mais fortes.\")\n",
    "            communities = community_louvain.best_partition(self.G_subset)\n",
    "            num_communities = len(set(communities.values()))\n",
    "            print(f\"  Número de comunidades detectadas: {num_communities}\")\n",
    "\n",
    "            # Armazenando os resultados na classe para uso posterior\n",
    "            self.centrality_measures = {\n",
    "                'degree': degree_centrality,\n",
    "                'betweenness': betweenness_centrality,\n",
    "                'closeness': closeness_centrality,\n",
    "                'eigenvector': eigenvector_centrality if 'eigenvector_centrality' in locals() else None\n",
    "            }\n",
    "            self.communities = communities\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao calcular as métricas: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090c4ec-5d3b-4d78-9172-948159775e21",
   "metadata": {},
   "source": [
    "\n",
    "> Como as Medidas São Calculadas?\n",
    "\n",
    "- Grau de Centralidade (Degree): O NetworkX realiza a contagem mais direta: para cada nó, ele simplesmente conta quantas arestas (conexões) estão ligadas a ele. Em uma rede social, isso mede a \"popularidade\" de um usuário pelo seu número de amigos diretos.\n",
    "    \n",
    "- Centralidade de Intermediação (Betweenness): O algoritmo identifica o caminho mais curto entre todos os pares de nós possíveis na rede. Em seguida, ele verifica cada nó individualmente e conta em quantos desses caminhos mais curtos ele aparece. Um nó com alta intermediação funciona como uma \"ponte\", sendo vital para a comunicação entre diferentes grupos da rede.\n",
    "    \n",
    "- Centralidade de Proximidade (Closeness): O algoritmo calcula a \"distância média\" de um nó para todos os outros nós da rede. Um nó com alta proximidade é aquele que precisa de poucos \"saltos\" para alcançar qualquer outra pessoa. É um nó posicionado de forma ideal para espalhar informações rapidamente por toda a rede.\n",
    "    \n",
    "- Centralidade de Autovetor (Eigenvector): Esta medida calcula a influência de um nó de forma recursiva. A ideia é que ter muitas conexões não é tudo, o mais importante é estar conectado a pessoas que também são importantes.O algoritmo atribui uma pontuação a cada nó baseada na soma das pontuações de seus vizinhos. Um nó com alto autovetor é um verdadeiro \"influenciador\", pois está conectado a outros influenciadores.\n",
    "    \n",
    "- Mapeamento de Comunidades (Louvain): O algoritmo de Louvain é um método iterativo que busca a melhor \"divisão\" da rede em comunidades. Ele faz isso tentando maximizar uma métrica chamada \"modularidade\", que é alta quando há muitas conexões \"dentro\" de um grupo e poucas conexões \"entre\" grupos diferentes. Ele agrupa os nós de forma a encontrar as \"panelinhas\" mais coesas e bem definidas da rede social.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d06fdf-c57f-45ab-ba1a-0ab48e33884a",
   "metadata": {},
   "source": [
    "## Etapa 4 - Visualizar o grafo e as medidas extraídas:\n",
    "\n",
    "- A biblioteca matplotlib é uma biblioteca do Python ideal para criar visualizações matemáticas, a matplotlib.pyplot é uma coleção de funções específicas para plotar grafos e gráficos. A função plt.figure cria uma imagem, que será a imagem do grafo.\n",
    "    \n",
    "- A função spring_layout é nativa do NetworkX e distribui os nós a partir do algoritmo de força direcionada de Fruchterman-Reingold. A utilização dessa distribuição para os nós foi por questão estética, o algoritmo precisa do número k que é a distância entre os nós e o número de iterações para o algoritmo convergir. A escolha de k=2 e iterations=1000 foram para deixar uma distribuição mais organizada.\n",
    "\n",
    "- O tamanho dos nós é variável de acordo com o grau dele, mas para a diferença visual não ser tão grande, foi utilizado o logaritmo do grau dos nós para criar uma lista com os tamanhos. O log()+1 evita erros com o log(0) que é indefinido.\n",
    " \n",
    "- A função percentile da biblioteca NumPy divide os graus em valores de porcentagem. Para os nós serem dividos em cores de acordo com o grau, o percentis divide os valores dos graus em porcentagens de 25%, 50%, 75% e 95%. O que significa que se 25% dos nós tem um certo valor de grau ou menor eles vão ter a mesma cor, nós utilizamos a paleta de cores \"plasma\" do matplotlib que faz com que os nós menos conectados sejam da cor azul e os mais da cor amarela. É dividido as cores de cada nó em 4 divisões de acordo com as porcentagens calculadas anteriormente, e é criado uma legenda explicando as cores de acordo com o grau dos nós, é variável a cada vez que é rodado o código, pois depende da porcentagem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90104072-ae22-4150-9478-3c15a98856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def visualizar_rede(self):\n",
    "        try:\n",
    "            if self.G_subset is None:\n",
    "                print(\"O subgrafo não existe!\")\n",
    "                return False\n",
    "\n",
    "            plt.figure(figsize=(20, 15))\n",
    "\n",
    "            pos = nx.spring_layout(self.G_subset, k=2, iterations=2000)\n",
    "\n",
    "            #Calcula o grau de cada nó coloca em um dicionário e o tamanho do nó é proporcional ao grau\n",
    "            graus = dict(self.G_subset.degree())\n",
    "            tamanhos = [np.log(graus[node]+1)*25 for node in self.G_subset.nodes()]\n",
    "\n",
    "            #Para melhor visualização no grafo, os nós tem cores de acordo com o grau\n",
    "            graus_valores = list(graus.values())\n",
    "            percentis = np.percentile(graus_valores, [25, 50, 75, 95])\n",
    "\n",
    "            node_colors = []\n",
    "            for node in self.G_subset.nodes():\n",
    "                if graus[node] <= percentis[0]:\n",
    "                    node_colors.append(0)\n",
    "                elif graus[node] <= percentis[1]:\n",
    "                    node_colors.append(1)\n",
    "                elif graus[node] <= percentis[2]:\n",
    "                    node_colors.append(2)\n",
    "                elif graus[node] <= percentis[3]:\n",
    "                    node_colors.append(3)\n",
    "                else:\n",
    "                    node_colors.append(4)\n",
    "            \n",
    "            #Definições de visualização\n",
    "            nx.draw_networkx_nodes(self.G_subset, pos, node_size=tamanhos, node_color=node_colors, cmap=\"plasma\", alpha=1)\n",
    "            nx.draw_networkx_edges(self.G_subset, pos, alpha=1, edge_color=\"gray\", width=0.5)\n",
    "\n",
    "            #Definição da legenda\n",
    "            legend_labels = [f\"Grau ≤ {int(percentis[0])}\", f\"Grau {int(percentis[0])+1}-{int(percentis[1])}\",\n",
    "                             f\"Grau {int(percentis[1])+1}-{int(percentis[2])}\", f\"Grau {int(percentis[2])+1}-{int(percentis[3])}\",\n",
    "                             f\"Grau > {int(percentis[3])}\"]\n",
    "            \n",
    "            cmap = plt.cm.plasma\n",
    "            legend_colors = [cmap(0.1), cmap(0.3), cmap(0.5), cmap(0.7), cmap(0.9)]\n",
    "\n",
    "            legend_elements = [Patch(facecolor=legend_colors[i], label=legend_labels[i], alpha=0.8) for i in range(5)]\n",
    "\n",
    "            plt.legend(handles=legend_elements, loc=\"upper right\", bbox_to_anchor=(1.15, 1.0), title=\"Legenda - Cores por Grau\",\n",
    "                  fontsize=10, framealpha=0.9)\n",
    "\n",
    "            plt.title(\"REDE FACEBOOK\", fontsize=16, pad=20)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro na visualização: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1314f54-acbc-4e94-b2bc-567464a4c915",
   "metadata": {},
   "source": [
    "\n",
    "# Método para poder visualizar as comunidades dentro do grafo:\n",
    "É utilizada a mesma distribuição do método anterior, porém a diferença é que as cores dos nós são a partir de uma lista dos valores das comunidades já calculadas anteriormente no método calcular_metricas()+1, pois as comunidades começam no 0, o que gera na visualização nós da mesma cor fazerem parte da mesma comunidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127624c4-81a9-4f5b-986c-ff9bac1ad182",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def visualizar_comunidades(self):\n",
    "        try:\n",
    "            if self.G_subset is None:\n",
    "                print(\"O subgrafo não existe!\")\n",
    "                return False\n",
    "\n",
    "            pos = nx.spring_layout(self.G_subset, k=2, iterations=1000)\n",
    "\n",
    "            #Calcula o grau de cada nó coloca em um dicionário e o tamanho do nó é proporcional ao grau\n",
    "            graus = dict(self.G_subset.degree())\n",
    "            tamanhos = [np.log(graus[node]+1)*25 for node in self.G_subset.nodes()]\n",
    "\n",
    "            cmap = plt.get_cmap(\"plasma\", max(self.communities.values())+1)\n",
    "            \n",
    "            #A cor de cada nó é a partir da lista de comunidades\n",
    "            nx.draw_networkx_nodes(self.G_subset, pos, node_color=list(self.communities.values()), cmap=plt.cm.plasma, node_size=tamanhos, alpha=1)\n",
    "            nx.draw_networkx_edges(self.G_subset, pos, alpha=1, edge_color=\"gray\", width=0.5)\n",
    "\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"COMUNIDADES\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na visualização: {e}\")\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ca900-3e70-48fb-8b83-4b15f0dc401f",
   "metadata": {},
   "source": [
    "\n",
    "# Função main:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca451e-2349-4e4f-ade0-7404c3e68a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    graph = FacebookGraph()\n",
    "\n",
    "    if not graph.baixar_dados():\n",
    "        return\n",
    "    \n",
    "    if not graph.carregar_rede():\n",
    "        return\n",
    "    \n",
    "    if not graph.extrair_subconjunto(2000):\n",
    "        return\n",
    "    \n",
    "    if not graph.calcular_metricas():\n",
    "        return\n",
    "\n",
    "    if not graph.visualizar_rede():\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3816ca2-c088-42f8-bcb8-a3febc80ff85",
   "metadata": {},
   "source": [
    "\n",
    "## Etapa 5 - Relatório de análise\n",
    "\n",
    "A análise relacionada à propriedade de cada nó ter maior influência, importância, potencial de espalhar informações ou outro está intrinsicamente relacionada às análises de centralidade. Dessa forma, como possuímos uma função para as centralidades, estaremos nos baseando nelas.\n",
    "\n",
    "###    - Grau de Centralidade:\n",
    "Medida que indica o número de conexões diretas que um nó possui. Nós com grau elevado tendem a ser usuários populares, conectados diretamente a muitos outros — o que os torna importantes para disseminação imediata de informações. Os cinco nós com maior grau de centralidade obtiveram valores entre 0.04 e 0.03, em aproximação, o que indica que cada um se conecta a cerca de 70–80 nós diretamente, sendo assim, esses são nós de maior influência.\n",
    "        \n",
    "###    - Centralidade de intermediação:\n",
    "Medida que avalia quantas vezes um nó aparece nos caminhos mais curtos entre outros pares de nós. Representam usuários mediadores, que têm acesso mais rápido a informações de diferentes comunidades e controlam parte do fluxo comunicacional entre elas. Dessa forma, são nós com maior potencial de receber informação.\n",
    "        \n",
    "###    - Centralidade de proximidade:\n",
    "Medida da distância média de um nó até todos os outros, nós com alta proximidade conseguem alcançar rapidamente todos os demais da rede. São nós centrais do ponto de vista estrutural, situados de forma estratégica com maior potencial de espalhar informação.\n",
    "\n",
    "###    - Centralidade de autovetor:\n",
    "Um nó tem alta centralidade de autovetor se está conectado a outros nós influentes. Informações iniciadas nesses nós têm maior probabilidade de atingir toda a rede, pois suas conexões diretas também possuem alta capacidade de difusão.\n",
    "        \n",
    "###    - Mapeamento de Comunidades (Algoritmo de Louvain) — Estrutura Social da Rede\n",
    "O algoritmo de Louvain identifica grupos densamente conectados dentro da rede. Cada comunidade representa um grupo social coeso, no qual as conexões internas são mais fortes que as externas — as “panelinhas” ou círculos de amizade da rede. Seu papel é compreender essas comunidades e permitir identificar subgrupos temáticos, interesses compartilhados ou bolhas informacionais.\n",
    "        \n",
    "Relação com as métricas: \n",
    "- Nós com alto grau tendem a ser centrais dentro de suas comunidades.\n",
    "- Nós com alta intermediação frequentemente conectam diferentes comunidades.\n",
    "- Nós com alta proximidade ou autovetor estão estrategicamente distribuídos entre comunidades."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
