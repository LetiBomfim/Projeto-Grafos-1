{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90104072-ae22-4150-9478-3c15a98856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projeto 1 de Grafos \n",
    "## Disciplina: Teoria dos Grafos — UnB\n",
    "## Turma: 01, 2025/2\n",
    "## Professor: Dibio\n",
    "### Integrantes:\n",
    "#- Julia Paulo Amorim - 241039270\n",
    "#- Leticia Gonçalves Bomfim - 241002411\n",
    "#- Vitor Alencar Ribeiro - 231036292\n",
    "\n",
    "##### Aqui descreveremos as instruções de quais extensões devem ser baixadas e como rodar o projeto para Linux\n",
    "    #1 - Verificar se python está instalado com python3 --version\n",
    "    #2  - Instalar o pip com sudo apt install python3-pip\n",
    "    #3 - Crie um ambiente virtual (se quiser) para rodar o projeto com python3 -m venv venv\n",
    "    #4 - Ative o ambiente virtual com source venv/bin/activate\n",
    "    #5 - Instale as dependências do projeto com pip install networkx numpy matplotlib community requests\n",
    "    #6 - Para rodar o projeto, utilize python3 facebook.py\n",
    "    #7 - Já em relação ao relatório, baixe o Jupyter notebook com pip install jupyterlab\n",
    "    #8 - Para iniciar o Jupyter, inicie o comando jupyter lab\n",
    "\n",
    "#Imports do grafo:\n",
    "import networkx as nx  #Manipula gráficos\n",
    "import requests  #Faz o download de dados por HTTP\n",
    "import numpy as np  #Auxilia nas operações numéricas\n",
    "import matplotlib.pyplot as plt  #Possibilita a visualização dos gráficos\n",
    "import community as community_louvain  #Detecta as comunidades\n",
    "from matplotlib.patches import Patch  #Possibilita a criação das legendas personalizadas\n",
    "\n",
    "#Etapa 1 - Coleta de Dados:\n",
    "\n",
    "class FacebookGraph:\n",
    "    #Esta classe baixa os dados do arquivo, carrega o grafo no Networkx, extrai o conjunto de 2000 nós, calcula as métricas de centralidade pedidas e visualiza a rede.\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.G = None\n",
    "        self.G_subset = None\n",
    "\n",
    "    def baixar_dados(self):\n",
    "        url = \"https://snap.stanford.edu/data/facebook_combined.txt.gz\"\n",
    "\n",
    "        try:\n",
    "            #Requests é uma biblioteca cliente HTTP para Python\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            #Abre o arquivo com as arestas\n",
    "            with open(\"facebook_combined.txt.gz\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(\"Arquivo aberto com sucesso!\\n\")\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Não foi possível abrir o arquivo: {e}\")\n",
    "            return False\n",
    "\n",
    "#Etapa 2 - Construir o grafo:\n",
    "    \n",
    "    def carregar_rede(self):\n",
    "        try:\n",
    "            #Função nativa do NetworkX que lê um arquivo de lista de arestas e cria um grafo\n",
    "            self.G = nx.read_edgelist(\"facebook_combined.txt.gz\")\n",
    "\n",
    "            #Teste se criou o grafo corretamente\n",
    "            print(f\" - Nós: {self.G.number_of_nodes()}\")          #4039\n",
    "            print(f\" - Arestas: {self.G.number_of_edges()}\")      #88234\n",
    "            print(f\" - Densidade: {nx.density(self.G):.6f}\")      #0.010820\n",
    "\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar grafo: {e}\")\n",
    "            return False\n",
    "            \n",
    "        #Parte da Etapa 1 - Extrair desse grafo carregado 2 mil vértices\n",
    "        \n",
    "    def extrair_subconjunto(self, n_nos=2000):\n",
    "        if self.G is None:\n",
    "            print(\"O grafo não existe!\")\n",
    "            return False\n",
    "        \n",
    "        todos_nos = list(self.G.nodes())\n",
    "        #Utiliza a biblioteca numpy para escolher nós aleatórios dentre os da lista\n",
    "        #replace=False é para não haver repetição de nós\n",
    "        nos_selecionados = np.random.choice(todos_nos, size=n_nos, replace=False)\n",
    "\n",
    "        #G_subset é o subgrafo com os 2000 selecionados\n",
    "        self.G_subset = self.G.subgraph(nos_selecionados).copy()\n",
    "\n",
    "        for node in nos_selecionados:\n",
    "            vizinhos = list(self.G.neighbors(node))\n",
    "            for vizinho in vizinhos:\n",
    "                if vizinho in nos_selecionados:\n",
    "                    self.G_subset.add_edge(node, vizinho)\n",
    "\n",
    "        print(\"\\nInformações gerais dos 2000 nós selecionados:\")\n",
    "        print(f\" - Nós: {self.G_subset.number_of_nodes()}\")\n",
    "        print(f\" - Arestas: {self.G_subset.number_of_edges()}\")\n",
    "        print(f\" - Densidade: {nx.density(self.G_subset):.6f}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "#Etapa 3 - Extrair do grafo as métricas:\n",
    "\n",
    "    def calcular_metricas(self, top_n=5):\n",
    "        #Calcula as métricas de centralidade e detecta comunidades no subgrafo.\n",
    "        if self.G_subset is None:\n",
    "            print(\"O subgrafo não existe! Execute extrair_subconjunto() primeiro.\")\n",
    "            return False\n",
    "        \n",
    "        print(\"\\n--- CALCULANDO MÉTRICAS DE CENTRALIDADE E COMUNIDADES ---\")\n",
    "        \n",
    "        try:\n",
    "            #Degree Centrality\n",
    "            print(\"\\n[1] Grau de Centralidade (Degree):\")\n",
    "            print(\"Mede a popularidade de um nó pelo número de conexões diretas.\")\n",
    "            degree_centrality = nx.degree_centrality(self.G_subset)\n",
    "            sorted_degree = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Grau de Centralidade:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_degree[i][0]}: {sorted_degree[i][1]:.4f}\")\n",
    "\n",
    "            #Betweenness Centrality\n",
    "            print(\"\\n[2] Centralidade de Intermediação (Betweenness):\")\n",
    "            print(\"Mede a importância de um nó como 'ponte' nos caminhos mais curtos entre outros nós.\")\n",
    "            betweenness_centrality = nx.betweenness_centrality(self.G_subset)\n",
    "            sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Centralidade de Intermediação:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_betweenness[i][0]}: {sorted_betweenness[i][1]:.4f}\")\n",
    "\n",
    "            #Closeness Centrality\n",
    "            print(\"\\n[3] Centralidade de Proximidade (Closeness):\")\n",
    "            print(\"Mede quão rápido um nó consegue alcançar todos os outros na rede.\")\n",
    "            closeness_centrality = nx.closeness_centrality(self.G_subset)\n",
    "            sorted_closeness = sorted(closeness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Centralidade de Proximidade:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_closeness[i][0]}: {sorted_closeness[i][1]:.4f}\")\n",
    "\n",
    "            #Eigenvector Centrality\n",
    "            print(\"\\n[4] Centralidade de Autovetor (Eigenvector):\")\n",
    "            print(\"Mede a influência de um nó com base na importância de seus vizinhos.\")\n",
    "            try:\n",
    "                eigenvector_centrality = nx.eigenvector_centrality(self.G_subset, max_iter=1000)\n",
    "                sorted_eigenvector = sorted(eigenvector_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "                print(f\"  Top {top_n} nós com maior Centralidade de Autovetor:\")\n",
    "                for i in range(top_n):\n",
    "                    print(f\"    {i+1}. Nó {sorted_eigenvector[i][0]}: {sorted_eigenvector[i][1]:.4f}\")\n",
    "            except nx.PowerIterationFailedConvergence:\n",
    "                print(\"  Cálculo de autovetor não convergiu. Pulando esta métrica.\")\n",
    "\n",
    "            #Algoritmo de Louvain\n",
    "            print(\"\\n[5] Mapeamento de Comunidades (Louvain):\")\n",
    "            print(\"Agrupa os nós em 'panelinhas' onde as conexões internas são mais fortes.\")\n",
    "            communities = community_louvain.best_partition(self.G_subset)\n",
    "            num_communities = len(set(communities.values()))\n",
    "            print(f\"  Número de comunidades detectadas: {num_communities}\")\n",
    "\n",
    "            # Armazenando os resultados na classe para uso posterior\n",
    "            self.centrality_measures = {\n",
    "                'degree': degree_centrality,\n",
    "                'betweenness': betweenness_centrality,\n",
    "                'closeness': closeness_centrality,\n",
    "                'eigenvector': eigenvector_centrality if 'eigenvector_centrality' in locals() else None\n",
    "            }\n",
    "            self.communities = communities\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao calcular as métricas: {e}\")\n",
    "            return False\n",
    "\n",
    "#Etapa 4 - Visualizar o grafo e as medidas extraídas\n",
    "    def visualizar_rede(self):\n",
    "        try:\n",
    "            if self.G_subset is None:\n",
    "                print(\"O subgrafo não existe!\")\n",
    "                return False\n",
    "            \n",
    "            plt.figure(figsize=(20, 15))\n",
    "\n",
    "            pos = nx.spring_layout(self.G_subset, k=2, iterations=2000)\n",
    "\n",
    "            #Calcula o grau de cada nó coloca em um dicionário e o tamanho do nó é proporcional ao grau\n",
    "            graus = dict(self.G_subset.degree())\n",
    "            tamanhos = [np.log(graus[node]+1)*25 for node in self.G_subset.nodes()]\n",
    "\n",
    "            #Para melhor visualização no grafo, os nós tem cores de acordo com o grau\n",
    "            graus_valores = list(graus.values())\n",
    "            percentis = np.percentile(graus_valores, [25, 50, 75, 95])\n",
    "\n",
    "            node_colors = []\n",
    "            for node in self.G_subset.nodes():\n",
    "                if graus[node] <= percentis[0]:\n",
    "                    node_colors.append(0)\n",
    "                elif graus[node] <= percentis[1]:\n",
    "                    node_colors.append(1)\n",
    "                elif graus[node] <= percentis[2]:\n",
    "                    node_colors.append(2)\n",
    "                elif graus[node] <= percentis[3]:\n",
    "                    node_colors.append(3)\n",
    "                else:\n",
    "                    node_colors.append(4)\n",
    "            \n",
    "            #Definições de visualização\n",
    "            nx.draw_networkx_nodes(self.G_subset, pos, node_size=tamanhos, node_color=node_colors, cmap=\"plasma\", alpha=1)\n",
    "            nx.draw_networkx_edges(self.G_subset, pos, alpha=1, edge_color=\"gray\", width=0.5)\n",
    "\n",
    "            #Definição da legenda\n",
    "            legend_labels = [f\"Grau ≤ {int(percentis[0])}\", f\"Grau ≤ {-int(percentis[0])+1 + int(percentis[1])}\",\n",
    "                             f\"Grau ≤ {-int(percentis[1])+1 + int(percentis[2])}\", f\"Grau ≤ {-int(percentis[2])+1 + int(percentis[3])}\",\n",
    "                             f\"Grau > {int(percentis[3])}\"]\n",
    "            \n",
    "            cmap = plt.cm.plasma\n",
    "            legend_colors = [cmap(0.1), cmap(0.3), cmap(0.5), cmap(0.7), cmap(0.9)]\n",
    "\n",
    "            legend_elements = [Patch(facecolor=legend_colors[i], label=legend_labels[i], alpha=0.8) for i in range(5)]\n",
    "\n",
    "            plt.legend(handles=legend_elements, loc=\"upper right\", bbox_to_anchor=(1.15, 1.0), title=\"Legenda - Cores por Grau\",\n",
    "                  fontsize=10, framealpha=0.9)\n",
    "\n",
    "            plt.title(\"REDE FACEBOOK\", fontsize=16, pad=20)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro na visualização: {e}\")\n",
    "            return False\n",
    "            \n",
    "        #Definição da main\n",
    "        def main():\n",
    "            graph = FacebookGraph()\n",
    "\n",
    "            if not graph.baixar_dados():\n",
    "                return\n",
    "    \n",
    "            if not graph.carregar_rede():\n",
    "                return\n",
    "    \n",
    "            if not graph.extrair_subconjunto(2000):\n",
    "                return\n",
    "    \n",
    "            if not graph.calcular_metricas():\n",
    "                return\n",
    "\n",
    "            if not graph.visualizar_rede():\n",
    "                return\n",
    "\n",
    "            if __name__ == \"__main__\":\n",
    "            main()\n",
    "\n",
    "#Etapa 5 - Relatório de análise\n",
    "#A análise relacionada à propriedade de cada nó ter maior influência, importância, potencial de espalhar informações ou outro \n",
    "#está intrinsicamente relacionada às análises de centralidade. Dessa forma, como possuímos uma função para as centralidades, estaremos nos baseando nelas.\n",
    "    #Grau de Centralidade \n",
    "        #Medida que indica o número de conexões diretas que um nó possui. Nós com grau elevado tendem a ser usuários populares, \n",
    "        #conectados diretamente a muitos outros — o que os torna importantes para disseminação imediata de informações. Os cinco nós com maior grau de centralidade obtiveram valores \n",
    "        #entre 0.04 e 0.03, em aproximação, o que indica que cada um se conecta a cerca de 70–80 nós diretamente, sendo assim, esses são nós de maior influência."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
