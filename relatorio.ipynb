{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90104072-ae22-4150-9478-3c15a98856cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#>> Projeto 1 de Grafos \n",
    "#>> Disciplina: Teoria dos Grafos — UnB\n",
    "#>> Turma: 01, 2025/2\n",
    "#>> Professor: Dibio\n",
    "#>>> Integrantes:\n",
    "#>- Julia Paulo Amorim - 241039270\n",
    "#>- Leticia Gonçalves Bomfim - 241002411\n",
    "#>- Vitor Alencar Ribeiro - 231036292\n",
    "\n",
    "#>>>>>> Aqui descreveremos as instruções de quais extensões devem ser baixadas e como rodar o projeto para Linux\n",
    "    #1 - Verificar se python está instalado com python3 --version\n",
    "    #2  - Instalar o pip com sudo apt install python3-pip\n",
    "    #3 - Crie um ambiente virtual (se quiser) para rodar o projeto com python3 -m venv venv\n",
    "    #4 - Ative o ambiente virtual com source venv/bin/activate\n",
    "    #5 - Instale as dependências do projeto com pip install networkx numpy matplotlib community requests\n",
    "    #6 - Para rodar o projeto, utilize python3 facebook.py\n",
    "    #7 - Já em relação ao relatório, baixe o Jupyter notebook com pip install jupyterlab\n",
    "    #8 - Para iniciar o Jupyter, inicie o comando jupyter lab\n",
    "\n",
    "#Imports do grafo:\n",
    "import networkx as nx  #Manipula gráficos\n",
    "import requests  #Faz o download de dados por HTTP\n",
    "import numpy as np  #Auxilia nas operações numéricas\n",
    "import matplotlib.pyplot as plt  #Possibilita a visualização dos gráficos\n",
    "import community as community_louvain  #Detecta as comunidades\n",
    "from matplotlib.patches import Patch  #Possibilita a criação das legendas personalizadas\n",
    "\n",
    "#Etapa 1 - Coleta de Dados:\n",
    "\n",
    "class FacebookGraph:\n",
    "    #> O processo envolve o download do arquivo compactado de arestas e a gravação local em disco, garantindo que o grafo possa ser carregado nas etapas seguintes.\n",
    "        #>> Como a Etapa Foi Implementada:\n",
    "    #>> -Download Automático: O método baixar_dados() utiliza uma requisição HTTP para acessar diretamente o dataset hospedado no site oficial da Universidade de Stanford\n",
    "    #>> (SNAP), onde está armazenado o grafo \"facebook_combined.txt.gz\".\n",
    "    #>> -Verificação de Sucesso: Caso o download seja bem-sucedido, o arquivo é salvo localmente e uma mensagem de confirmação é exibida; caso contrário, o erro é\n",
    "    #>> tratado e descrito no terminal.\n",
    "        #>> Bibliotecas Escolhidas:\n",
    "    #>> -Requests: A biblioteca `requests` é a ferramenta padrão e mais estável em Python para comunicações HTTP. Foi escolhida por sua simplicidade, confiabilidade e por\n",
    "    #>> permitir o tratamento direto de exceções (com o método raise_for_status), evitando falhas silenciosas durante o download.\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.G = None\n",
    "        self.G_subset = None\n",
    "\n",
    "    def baixar_dados(self):\n",
    "        url = \"https://snap.stanford.edu/data/facebook_combined.txt.gz\"\n",
    "\n",
    "        try:\n",
    "            #Requests é uma biblioteca cliente HTTP para Python\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            #Abre o arquivo com as arestas\n",
    "            with open(\"facebook_combined.txt.gz\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(\"Arquivo aberto com sucesso!\\n\")\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Não foi possível abrir o arquivo: {e}\")\n",
    "            return False\n",
    "\n",
    "#Etapa 2 - Construir o grafo:\n",
    "     #>> Esta etapa cumpre a segunda parte do projeto: transformar os dados baixados em uma estrutura de grafo manipulável e gerar um subgrafo com 2000 nós para análises\n",
    "     #>> subsequentes.\n",
    "        #>> Como a Etapa Foi Implementada:\n",
    "    #>> -Carregamento da Rede: O método carregar_rede() usa uma função nativa do NetworkX que interpreta automaticamente o arquivo de lista de arestas (.txt.gz) e cria um\n",
    "    #>> grafo não direcionado. Em seguida, são impressas métricas básicas — número de nós, arestas e densidade — que servem como uma validação inicial do dataset.\n",
    "    #>> -Seleção Aleatória de Nós: O método extrair_subconjunto() faz uma amostragem aleatória de 2000 vértices do grafo principal. Essa abordagem reduz a complexidade\n",
    "    #>> computacional e permite que o restante da análise (centralidades e comunidades) seja executado de forma eficiente.\n",
    "    #>> -Construção do Subgrafo: Após a seleção, é criado um subgrafo contendo apenas os nós sorteados e suas arestas internas. Assim, garante-se que o subconjunto\n",
    "    #>> preserve a estrutura original de conexões entre os nós escolhidos.\n",
    "        #>> Bibliotecas Escolhidas:\n",
    "    #>> -NetworkX: É a principal biblioteca Python para modelagem e análise de grafos. Ela permite ler o arquivo de arestas diretamente e fornece métodos prontos\n",
    "    #>> para criar subgrafos, calcular densidade e realizar inspeções estruturais.\n",
    "    #>> -NumPy: Utilizada aqui pela função `np.random.choice`, que oferece uma maneira eficiente e reproduzível de selecionar nós aleatórios sem repetição\n",
    "    #>> (replace=False), garantindo uma amostragem equilibrada da rede.\n",
    "        \n",
    "    def carregar_rede(self):\n",
    "        try:\n",
    "            #Função nativa do NetworkX que lê um arquivo de lista de arestas e cria um grafo\n",
    "            self.G = nx.read_edgelist(\"facebook_combined.txt.gz\")\n",
    "\n",
    "            #Teste se criou o grafo corretamente\n",
    "            print(f\" - Nós: {self.G.number_of_nodes()}\")          #4039\n",
    "            print(f\" - Arestas: {self.G.number_of_edges()}\")      #88234\n",
    "            print(f\" - Densidade: {nx.density(self.G):.6f}\")      #0.010820\n",
    "\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar grafo: {e}\")\n",
    "            return False\n",
    "            \n",
    "        #Parte da Etapa 1 - Extrair desse grafo carregado 2 mil vértices\n",
    "        \n",
    "    def extrair_subconjunto(self, n_nos=2000):\n",
    "        if self.G is None:\n",
    "            print(\"O grafo não existe!\")\n",
    "            return False\n",
    "        \n",
    "        todos_nos = list(self.G.nodes())\n",
    "        #Utiliza a biblioteca numpy para escolher nós aleatórios dentre os da lista\n",
    "        #replace=False é para não haver repetição de nós\n",
    "        nos_selecionados = np.random.choice(todos_nos, size=n_nos, replace=False)\n",
    "\n",
    "        #G_subset é o subgrafo com os 2000 selecionados\n",
    "        self.G_subset = self.G.subgraph(nos_selecionados).copy()\n",
    "\n",
    "        for node in nos_selecionados:\n",
    "            vizinhos = list(self.G.neighbors(node))\n",
    "            for vizinho in vizinhos:\n",
    "                if vizinho in nos_selecionados:\n",
    "                    self.G_subset.add_edge(node, vizinho)\n",
    "\n",
    "        print(\"\\nInformações gerais dos 2000 nós selecionados:\")\n",
    "        print(f\" - Nós: {self.G_subset.number_of_nodes()}\")\n",
    "        print(f\" - Arestas: {self.G_subset.number_of_edges()}\")\n",
    "        print(f\" - Densidade: {nx.density(self.G_subset):.6f}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "#Etapa 3 - Extrair do grafo as métricas:\n",
    "    #>> Este bloco de código foi desenvolvido para cumprir a Etapa 3 do projeto, que exige a extração de métricas de centralidade e o mapeamento de\n",
    "    #>> comunidades da rede social. A implementação foi feita dentro do método calcular_metricas() para manter a organização e a modularidade do código.7\n",
    "    \n",
    "     #>> Como a Análise Foi Implementada: O método calcular_metricas() segue uma lógica sequencial e clara:\n",
    "        #>> -Centralização: Todas as análises foram agrupadas em uma única função para facilitar a execução e a manutenção do código.\n",
    "        #>> -Cálculo das Métricas: Para cada uma das quatro medidas de centralidade (Grau, Intermediação, Proximidade e Autovetor), o código chama uma função\n",
    "        #>> específica e otimizada da biblioteca NetworkX.\n",
    "        #>> -Identificação dos Nós Influentes: Após cada cálculo, o código ordena os resultados e imprime no terminal os 5 nós mais importantes (o \"Top 5\")\n",
    "        #>> para aquela métrica. Isso fornece uma visão imediata de quais \"usuários\" são mais influentes em diferentes aspectos da rede, informação crucial\n",
    "        #>> para o relatório final.\n",
    "        #>> -Detecção de Comunidades: Utiliza-se a biblioteca community para aplicar o algoritmo de Louvain, conforme exigido pelo enunciado do projeto,\n",
    "        #>> identificando os principais agrupamentos (\"panelinhas\") na rede.\n",
    "        #>> -Armazenamento: Todos os resultados são salvos em variáveis da classe, permitindo que sejam facilmente acessados por outras funções, como a de\n",
    "        #>> visualização, para criar os grafos coloridos e rotulados.\n",
    "\n",
    "     #>> Bibliotecas Escolhidas:\n",
    "        #>>A escolha das bibliotecas foi baseada nas que mais fazem sentido nos requisitos do projeto:\n",
    "        #>> -NetworkX: É a biblioteca padrão-ouro para análise de grafos em Python, [cite_start]explicitamente recomendada nas instruções do trabalho[cite: 1158]. A principal\n",
    "        #>> vantagem é que ela já possui implementações robustas e academicamente validadas de todos os algoritmos de centralidade necessários. Isso elimina a necessidade de programar \n",
    "        #>> essas complexas rotinas matemáticas do zero, garantindo a precisão dos resultados e a simplicidade do código.\n",
    "        #>> -Python-louvain (importada como community): O enunciado do projeto exige [cite_start]especificamente o \"Mapeamento de comunidades pelo algoritmo de Louvain\"[cite: 1150].\n",
    "        #>> A biblioteca python-louvain é a implementação padrão deste método para Python e se integra perfeitamente com objetos de grafo do NetworkX.\n",
    "        #>> A escolha, portanto, foi a mais direta para cumprir este requisito.\n",
    "\n",
    "\n",
    "    def calcular_metricas(self, top_n=5):\n",
    "        #Calcula as métricas de centralidade e detecta comunidades no subgrafo.\n",
    "        if self.G_subset is None:\n",
    "            print(\"O subgrafo não existe! Execute extrair_subconjunto() primeiro.\")\n",
    "            return False\n",
    "        \n",
    "        print(\"\\n--- CALCULANDO MÉTRICAS DE CENTRALIDADE E COMUNIDADES ---\")\n",
    "        \n",
    "        try:\n",
    "            #Degree Centrality\n",
    "            print(\"\\n[1] Grau de Centralidade (Degree):\")\n",
    "            print(\"Mede a popularidade de um nó pelo número de conexões diretas.\")\n",
    "            degree_centrality = nx.degree_centrality(self.G_subset)\n",
    "            sorted_degree = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Grau de Centralidade:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_degree[i][0]}: {sorted_degree[i][1]:.4f}\")\n",
    "\n",
    "            #Betweenness Centrality\n",
    "            print(\"\\n[2] Centralidade de Intermediação (Betweenness):\")\n",
    "            print(\"Mede a importância de um nó como 'ponte' nos caminhos mais curtos entre outros nós.\")\n",
    "            betweenness_centrality = nx.betweenness_centrality(self.G_subset)\n",
    "            sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Centralidade de Intermediação:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_betweenness[i][0]}: {sorted_betweenness[i][1]:.4f}\")\n",
    "\n",
    "            #Closeness Centrality\n",
    "            print(\"\\n[3] Centralidade de Proximidade (Closeness):\")\n",
    "            print(\"Mede quão rápido um nó consegue alcançar todos os outros na rede.\")\n",
    "            closeness_centrality = nx.closeness_centrality(self.G_subset)\n",
    "            sorted_closeness = sorted(closeness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "            print(f\"  Top {top_n} nós com maior Centralidade de Proximidade:\")\n",
    "            for i in range(top_n):\n",
    "                print(f\"    {i+1}. Nó {sorted_closeness[i][0]}: {sorted_closeness[i][1]:.4f}\")\n",
    "\n",
    "            #Eigenvector Centrality\n",
    "            print(\"\\n[4] Centralidade de Autovetor (Eigenvector):\")\n",
    "            print(\"Mede a influência de um nó com base na importância de seus vizinhos.\")\n",
    "            try:\n",
    "                eigenvector_centrality = nx.eigenvector_centrality(self.G_subset, max_iter=1000)\n",
    "                sorted_eigenvector = sorted(eigenvector_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "                print(f\"  Top {top_n} nós com maior Centralidade de Autovetor:\")\n",
    "                for i in range(top_n):\n",
    "                    print(f\"    {i+1}. Nó {sorted_eigenvector[i][0]}: {sorted_eigenvector[i][1]:.4f}\")\n",
    "            except nx.PowerIterationFailedConvergence:\n",
    "                print(\"  Cálculo de autovetor não convergiu. Pulando esta métrica.\")\n",
    "\n",
    "            #Algoritmo de Louvain\n",
    "            print(\"\\n[5] Mapeamento de Comunidades (Louvain):\")\n",
    "            print(\"Agrupa os nós em 'panelinhas' onde as conexões internas são mais fortes.\")\n",
    "            communities = community_louvain.best_partition(self.G_subset)\n",
    "            num_communities = len(set(communities.values()))\n",
    "            print(f\"  Número de comunidades detectadas: {num_communities}\")\n",
    "\n",
    "            # Armazenando os resultados na classe para uso posterior\n",
    "            self.centrality_measures = {\n",
    "                'degree': degree_centrality,\n",
    "                'betweenness': betweenness_centrality,\n",
    "                'closeness': closeness_centrality,\n",
    "                'eigenvector': eigenvector_centrality if 'eigenvector_centrality' in locals() else None\n",
    "            }\n",
    "            self.communities = communities\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao calcular as métricas: {e}\")\n",
    "            return False\n",
    "\n",
    "    #>> Como as Medidas São Calculadas?\n",
    "\n",
    "       #>> -Grau de Centralidade (Degree): O NetworkX realiza a contagem mais direta: para cada nó, ele simplesmente conta quantas arestas (conexões) estão\n",
    "    #>> ligadas a ele. Em uma rede social, isso mede a \"popularidade\" de um usuário pelo seu número de amigos diretos.\n",
    "        #>> -Centralidade de Intermediação (Betweenness): O algoritmo identifica o caminho mais curto entre todos os pares de nós possíveis na rede. Em\n",
    "    #>> seguida, ele verifica cada nó individualmente e conta em quantos desses caminhos mais curtos ele aparece. Um nó com alta intermediação funciona\n",
    "    #>> como uma \"ponte\", sendo vital para a comunicação entre diferentes grupos da rede.\n",
    "        #>> -Centralidade de Proximidade (Closeness): O algoritmo calcula a \"distância média\" de um nó para todos os outros nós da rede. Um nó com alta\n",
    "    #>> proximidade é aquele que precisa de poucos \"saltos\" para alcançar qualquer outra pessoa. É um nó posicionado de forma ideal para espalhar\n",
    "    #>> informações rapidamente por toda a rede.\n",
    "        #>> -Centralidade de Autovetor (Eigenvector): Esta medida calcula a influência de um nó de forma recursiva. A ideia é que ter muitas conexões não é tudo,\n",
    "    #>> o mais importante é estar conectado a pessoas que também são importantes.O algoritmo atribui uma pontuação a cada nó baseada na soma das\n",
    "    #>> pontuações de seus vizinhos. Um nó com alto autovetor é um verdadeiro \"influenciador\", pois está conectado a outros influenciadores.\n",
    "        #>> -Mapeamento de Comunidades (Louvain): O algoritmo de Louvain é um método iterativo que busca a melhor \"divisão\" da rede em comunidades. Ele faz\n",
    "    #>> isso tentando maximizar uma métrica chamada \"modularidade\", que é alta quando há muitas conexões \"dentro\" de um grupo e poucas conexões \"entre\"\n",
    "    #>> grupos diferentes. Ele agrupa os nós de forma a encontrar as \"panelinhas\" mais coesas e bem definidas da rede social.\n",
    "\n",
    "\n",
    "    #Etapa 4 - Visualizar o grafo e as medidas extraídas\n",
    "    def visualizar_rede(self):\n",
    "        try:\n",
    "            if self.G_subset is None:\n",
    "                print(\"O subgrafo não existe!\")\n",
    "                return False\n",
    "\n",
    "    #>> A biblioteca matplotlib é uma biblioteca do Python ideal para criar visualizações matemáticas, a matplotlib.pyplot é uma coleção de funções específicas para plotar grafos e \n",
    "    #>> gráficos.\n",
    "    #>> A função plt.figure cria uma imagem.\n",
    "\n",
    "            plt.figure(figsize=(20, 15))\n",
    "\n",
    "    #>> A função spring_layout é nativa do NetworkX e distribui os nós a partir do algoritmo de força direcionada de Fruchterman-Reingold\n",
    "    #>> A utilização dessa distribuição para os nós foi por questão estética, o algoritmo precisa do número k que é a distância entre os nós e o número de iterações para o algoritmo \n",
    "    #>> convergir. A escolha de k=2 e iterations=1000 foram para deixar uma distribuição mais organizada.\n",
    "\n",
    "            pos = nx.spring_layout(self.G_subset, k=2, iterations=2000)\n",
    "\n",
    "    #>> O tamanho dos nós é variável de acordo com o grau dele, mas para a diferença visual não ser tão grande, foi utilizado o logaritmo do grau dos nós para criar uma lista com os \n",
    "    #>> tamanhos. O log()+1 evita erros com o log(0) que é indefinido.\n",
    "\n",
    "            #Calcula o grau de cada nó coloca em um dicionário e o tamanho do nó é proporcional ao grau\n",
    "            graus = dict(self.G_subset.degree())\n",
    "            tamanhos = [np.log(graus[node]+1)*25 for node in self.G_subset.nodes()]\n",
    "\n",
    "    #>> A função percentile da biblioteca NumPy divide os graus em valores de porcentagem. Para os nós serem dividos em cores de acordo com o grau, o percentis divide os valores dos \n",
    "    #>> graus em porcentagens de 25%, 50%, 75% e 95%. O que significa que se 25% dos nós tem um certo valor de grau ou menor eles vão ter a mesma cor, nós utilizamos a paleta de \n",
    "    #>> cores \"plasma\" do matplotlib que faz com que os nós menos conectados sejam da cor azul e os mais da cor amarela.\n",
    "\n",
    "            #Para melhor visualização no grafo, os nós tem cores de acordo com o grau\n",
    "            graus_valores = list(graus.values())\n",
    "            percentis = np.percentile(graus_valores, [25, 50, 75, 95])\n",
    "\n",
    "    #>> Divide as cores de cada nó em 4 divisões de acordo com as porcentagens calculadas anteriormente\n",
    "\n",
    "            node_colors = []\n",
    "            for node in self.G_subset.nodes():\n",
    "                if graus[node] <= percentis[0]:\n",
    "                    node_colors.append(0)\n",
    "                elif graus[node] <= percentis[1]:\n",
    "                    node_colors.append(1)\n",
    "                elif graus[node] <= percentis[2]:\n",
    "                    node_colors.append(2)\n",
    "                elif graus[node] <= percentis[3]:\n",
    "                    node_colors.append(3)\n",
    "                else:\n",
    "                    node_colors.append(4)\n",
    "            \n",
    "            #Definições de visualização\n",
    "            nx.draw_networkx_nodes(self.G_subset, pos, node_size=tamanhos, node_color=node_colors, cmap=\"plasma\", alpha=1)\n",
    "            nx.draw_networkx_edges(self.G_subset, pos, alpha=1, edge_color=\"gray\", width=0.5)\n",
    "\n",
    "    #>> Cria uma legenda explicando as cores de acordo com o grau dos nós, é variável a cada vez que é rodado o código, pois depende da porcentagem\n",
    "\n",
    "            #Definição da legenda\n",
    "            legend_labels = [f\"Grau ≤ {int(percentis[0])}\", f\"Grau {int(percentis[0])+1}-{int(percentis[1])}\",\n",
    "                             f\"Grau {int(percentis[1])+1}-{int(percentis[2])}\", f\"Grau {int(percentis[2])+1}-{int(percentis[3])}\",\n",
    "                             f\"Grau > {int(percentis[3])}\"]\n",
    "            \n",
    "            cmap = plt.cm.plasma\n",
    "            legend_colors = [cmap(0.1), cmap(0.3), cmap(0.5), cmap(0.7), cmap(0.9)]\n",
    "\n",
    "            legend_elements = [Patch(facecolor=legend_colors[i], label=legend_labels[i], alpha=0.8) for i in range(5)]\n",
    "\n",
    "            plt.legend(handles=legend_elements, loc=\"upper right\", bbox_to_anchor=(1.15, 1.0), title=\"Legenda - Cores por Grau\",\n",
    "                  fontsize=10, framealpha=0.9)\n",
    "\n",
    "            plt.title(\"REDE FACEBOOK\", fontsize=16, pad=20)\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro na visualização: {e}\")\n",
    "            return False\n",
    "        \n",
    "    #>> Método para poder visualizar as comunidades dentro do grafo\n",
    "    def visualizar_comunidades(self):\n",
    "        try:\n",
    "            if self.G_subset is None:\n",
    "                print(\"O subgrafo não existe!\")\n",
    "                return False\n",
    "\n",
    "    #>> Mesma distribuição do método anterior\n",
    "\n",
    "            pos = nx.spring_layout(self.G_subset, k=2, iterations=1000)\n",
    "\n",
    "            #Calcula o grau de cada nó coloca em um dicionário e o tamanho do nó é proporcional ao grau\n",
    "            graus = dict(self.G_subset.degree())\n",
    "            tamanhos = [np.log(graus[node]+1)*25 for node in self.G_subset.nodes()]\n",
    "\n",
    "    #>> As cores dos nós são a partir de uma lista dos valores das comunidades já calculadas anteriormente no método calcular_metricas()+1, pois as comunidades começam no 0, o que \n",
    "    #>> gera na visualização nós da mesma cor fazerem parte da mesma comunidade.\n",
    "\n",
    "            cmap = plt.cm.get_cmap(\"plasma\", max(self.communities.values())+1)\n",
    "            \n",
    "            #A cor de cada nó é a partir da lista de comunidades\n",
    "            nx.draw_networkx_nodes(self.G_subset, pos, node_color=list(self.communities.values()), cmap=plt.cm.plasma, node_size=tamanhos, alpha=1)\n",
    "            nx.draw_networkx_edges(self.G_subset, pos, alpha=1, edge_color=\"gray\", width=0.5)\n",
    "\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"COMUNIDADES\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na visualização: {e}\")\n",
    "            return False\n",
    "        \n",
    "            \n",
    "#Definição da main\n",
    "def main():\n",
    "    graph = FacebookGraph()\n",
    "\n",
    "    if not graph.baixar_dados():\n",
    "        return\n",
    "    \n",
    "    if not graph.carregar_rede():\n",
    "        return\n",
    "    \n",
    "    if not graph.extrair_subconjunto(2000):\n",
    "        return\n",
    "    \n",
    "    if not graph.calcular_metricas():\n",
    "        return\n",
    "\n",
    "    if not graph.visualizar_rede():\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "#Etapa 5 - Relatório de análise\n",
    "    #>> A análise relacionada à propriedade de cada nó ter maior influência, importância, potencial de espalhar informações ou outro \n",
    "    #>> está intrinsicamente relacionada às análises de centralidade. Dessa forma, como possuímos uma função para as centralidades, estaremos nos baseando nelas.\n",
    "        #>> Grau de Centralidade:\n",
    "            #>> Medida que indica o número de conexões diretas que um nó possui. Nós com grau elevado tendem a ser usuários populares, \n",
    "            #>> conectados diretamente a muitos outros — o que os torna importantes para disseminação imediata de informações. Os cinco nós com maior grau de centralidade obtiveram \n",
    "            #>> valores entre 0.04 e 0.03, em aproximação, o que indica que cada um se conecta a cerca de 70–80 nós diretamente, sendo assim, esses são nós de maior influência.\n",
    "        #>> Centralidade de intermediação:\n",
    "            #>> Medida que avalia quantas vezes um nó aparece nos caminhos mais curtos entre outros pares de nós. Representam usuários mediadores, que têm acesso mais rápido \n",
    "            #>> a informações de diferentes comunidades e controlam parte do fluxo comunicacional entre elas. Dessa forma, são nós com maior potencial de receber informação.\n",
    "        #>> Centralidade de proximidade:\n",
    "            #>> Medida da distância média de um nó até todos os outros, nós com alta proximidade conseguem alcançar rapidamente todos os demais da rede.\n",
    "            #>> São nós centrais do ponto de vista estrutural, situados de forma estratégica com maior potencial de espalhar informação.\n",
    "        #>> Centralidade de autovetor:\n",
    "            #>> Um nó tem alta centralidade de autovetor se está conectado a outros nós influentes.\n",
    "            #>> Informações iniciadas nesses nós têm maior probabilidade de atingir toda a rede, pois suas conexões diretas também possuem alta capacidade de difusão.\n",
    "        #>> Mapeamento de Comunidades (Algoritmo de Louvain) — Estrutura Social da Rede\n",
    "            #>> O algoritmo de Louvain identifica grupos densamente conectados dentro da rede. Cada comunidade representa um grupo social coeso, no qual as conexões internas \n",
    "            #>> são mais fortes que as externas — as “panelinhas” ou círculos de amizade da rede. Seu papel é compreender essas comunidades e permitir identificar subgrupos \n",
    "            #>> temáticos, interesses compartilhados ou bolhas informacionais.\n",
    "            #>> Relação com as métricas: \n",
    "                    #>> Nós com alto grau tendem a ser centrais dentro de suas comunidades.\n",
    "                    #>> Nós com alta intermediação frequentemente conectam diferentes comunidades.\n",
    "                    #>> Nós com alta proximidade ou autovetor estão estrategicamente distribuídos entre comunidades."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
